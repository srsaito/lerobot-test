diff --git a/examples/2_evaluate_pretrained_policy.py b/examples/2_evaluate_pretrained_policy.py
index 4e6154c2..9e8da5d7 100644
--- a/examples/2_evaluate_pretrained_policy.py
+++ b/examples/2_evaluate_pretrained_policy.py
@@ -36,8 +36,15 @@ from lerobot.common.policies.diffusion.modeling_diffusion import DiffusionPolicy
 output_directory = Path("outputs/eval/example_pusht_diffusion")
 output_directory.mkdir(parents=True, exist_ok=True)
 
-# Select your device
-device = "cuda"
+# Select your device - auto-detect best available device
+if torch.cuda.is_available():
+    device = "cuda"
+elif torch.backends.mps.is_available():
+    device = "mps"
+else:
+    device = "cpu"
+
+print(f"Using device: {device}")
 
 # Provide the [hugging face repo id](https://huggingface.co/lerobot/diffusion_pusht):
 pretrained_policy_path = "lerobot/diffusion_pusht"
@@ -67,7 +74,7 @@ print(env.action_space)
 
 # Reset the policy and environments to prepare for rollout
 policy.reset()
-numpy_observation, info = env.reset(seed=42)
+numpy_observation, info = env.reset(seed=129)
 
 # Prepare to collect every rewards and all the frames of the episode,
 # from initial state to final state.
@@ -90,9 +97,13 @@ while not done:
     image = image.to(torch.float32) / 255
     image = image.permute(2, 0, 1)
 
-    # Send data tensors from CPU to GPU
-    state = state.to(device, non_blocking=True)
-    image = image.to(device, non_blocking=True)
+    # Send data tensors from CPU to GPU/MPS - use non_blocking only for CUDA
+    if device == "cuda":
+        state = state.to(device, non_blocking=True)
+        image = image.to(device, non_blocking=True)
+    else:
+        state = state.to(device)
+        image = image.to(device)
 
     # Add extra (empty) batch dimension, required to forward the policy
     state = state.unsqueeze(0)
diff --git a/lerobot/scripts/train.py b/lerobot/scripts/train.py
index 0de247be..1c4a7164 100644
--- a/lerobot/scripts/train.py
+++ b/lerobot/scripts/train.py
@@ -48,6 +48,7 @@ from lerobot.common.utils.utils import (
     init_logging,
 )
 from lerobot.common.utils.wandb_utils import WandBLogger
+from lerobot.common.utils.tensorboard_utils import TensorBoardLogger
 from lerobot.configs import parser
 from lerobot.configs.train import TrainPipelineConfig
 from lerobot.scripts.eval import eval_policy
@@ -116,6 +117,12 @@ def train(cfg: TrainPipelineConfig):
         wandb_logger = None
         logging.info(colored("Logs will be saved locally.", "yellow", attrs=["bold"]))
 
+    # TensorBoard logger
+    if cfg.tensorboard.enable:
+        tensorboard_logger = TensorBoardLogger(cfg)
+    else:
+        tensorboard_logger = None
+
     if cfg.seed is not None:
         set_seed(cfg.seed)
 
@@ -235,6 +242,11 @@ def train(cfg: TrainPipelineConfig):
                 if output_dict:
                     wandb_log_dict.update(output_dict)
                 wandb_logger.log_dict(wandb_log_dict, step)
+            if tensorboard_logger:
+                tb_log_dict = train_tracker.to_dict()
+                if output_dict:
+                    tb_log_dict.update(output_dict)
+                tensorboard_logger.log_dict(tb_log_dict, step, mode="train")
             train_tracker.reset_averages()
 
         if cfg.save_checkpoint and is_saving_step:
@@ -277,9 +289,14 @@ def train(cfg: TrainPipelineConfig):
                 wandb_log_dict = {**eval_tracker.to_dict(), **eval_info}
                 wandb_logger.log_dict(wandb_log_dict, step, mode="eval")
                 wandb_logger.log_video(eval_info["video_paths"][0], step, mode="eval")
+            if tensorboard_logger:
+                tb_log_dict = {**eval_tracker.to_dict(), **eval_info}
+                tensorboard_logger.log_dict(tb_log_dict, step, mode="eval")
 
     if eval_env:
         eval_env.close()
+    if tensorboard_logger:
+        tensorboard_logger.close()
     logging.info("End of training")
 
 
diff --git a/pyproject.toml b/pyproject.toml
index 5bff0fca..72c2943d 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -103,6 +103,7 @@ test = ["pytest>=8.1.0", "pytest-timeout>=2.4.0", "pytest-cov>=5.0.0", "pyserial
 hilserl = ["transformers>=4.50.3", "gym-hil>=0.1.8", "protobuf>=5.29.3", "grpcio==1.71.0"]
 umi = ["imagecodecs>=2024.1.1"]
 video_benchmark = ["scikit-image>=0.23.2", "pandas>=2.2.2"]
+visualization = ["matplotlib>=3.10.0", "seaborn>=0.13.0"]
 xarm = ["gym-xarm>=0.1.1 ; python_version < '4.0'"]
 
 [tool.poetry]
